---
status: accepted
date: 2025-06-08
decision-makers: [Whole team]
consulted: [Course materials (labs), teammates]
informed: [Whole team]
---

# Use of Jest for Testing and Code Coverage

## Context and Problem Statement

As our codebase grew, we needed a way to ensure that functionality remained stable while continuing to develop new features (to put into our CICD pipeline). We needed a simple, effective, and course-aligned framework for testing JavaScript functions and DOM behavior in both unit and integration scenarios. We also wanted to measure how much of our code is being tested—code coverage—without introducing overly complex tools.

## Decision Drivers

* Alignment with course guidelines and expectations, not spreading tool use
* Simplicity of configuration and integration
* Simple code coverage support/addition

## Considered Options

* Jest
* Mocha + Chai
* Jasmine

## Decision Outcome

Chosen option: **Jest**, because it integrates seamlessly into the Node.js ecosystem, provides built-in support for code coverage, and is officially recommended in the course materials. It also supports mocking, snapshot testing, and asynchronous testing with minimal configuration, which aligned well with our scope.

### Consequences

* Good, because adding tests was straightforward, requiring minimal setup.
* Good, because generating code coverage reports was as simple as running `jest --coverage`.
* Good, because it's widely used and well-documented.
* Bad, because it’s less tailored to E2E testing or full browser automation (supplemented with Playwright).

## Confirmation

The implementation is confirmed through GitHub Actions, which automatically runs `jest` tests and fails the pipeline if any test fails. Code coverage reports are also generated and reviewed as part of the CI process, and can be viewed in a simple table in the CI pipeline's output. 

## Pros and Cons of the Options

### Jest

* Good, because setup is minimal and integrated with most JavaScript tooling.
* Good, because it's supported in the course and many team members were already familiar with it.
* Good, because coverage reporting works out-of-the-box (`--coverage`).
* Neutral, because some advanced test configurations (e.g., custom environments) require plugins or tweaks.
* Bad, because it's not built for true browser testing—but that wasn't a key requirement.

### Mocha + Chai

* Good, because of flexibility and long-standing usage in the industry.
* Bad, because you need to manually configure coverage and async handling.
* Bad, because it's more verbose and not course-aligned.

### Jasmine

* Good, because of built-in assertions and spies.
* Bad, because it’s not as commonly used in modern JS tooling stacks.

## More Information

* Jest documentation: [https://jestjs.io/docs](https://jestjs.io/docs)
* Our repo includes a `__tests__/` directory with our `jest` tests
* Code coverage thresholds are shown in CI outputs and can be enforced if needed.
